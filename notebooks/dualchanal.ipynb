{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7OxPotkACpv",
        "outputId": "338b16e6-ea0a-4277-96f8-f5e83bc8e108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input , Dense ,Dropout\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from scipy.sparse import vstack\n",
        "import bz2\n",
        "import numpy as np\n",
        "import pickle\n",
        "import mmap \n",
        "import re"
      ],
      "metadata": {
        "id": "bEaYF_FiA_aX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MAX_FEATURES = 12000\n",
        "sequences = Input(shape=(255,))\n",
        "embedded = layers.Embedding(MAX_FEATURES, 32)(sequences)\n",
        "x = layers.Conv1D(64, 3, activation='relu')(embedded)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPool1D(3)(x)\n",
        "x = layers.Conv1D(32, 5, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPool1D(5)(x)\n",
        "x = layers.Conv1D(16, 5, activation='relu')(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)"
      ],
      "metadata": {
        "id": "2bIqdVZ6BBLz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = Input(shape=(1000,))\n",
        "x1 = layers.Dense(128, activation='relu')(tfidf)\n",
        "x1 = layers.Dense(64, activation='relu')(x1)\n",
        "     "
      ],
      "metadata": {
        "id": "1ayCJ7ZcBCut"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged = layers.concatenate([x, x1])\n"
      ],
      "metadata": {
        "id": "3A9e5hUmBIOu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = Dense(256, activation='relu')(merged)\n",
        "dense1 = Dropout(0.1)(dense1)\n",
        "dense1 = Dense(32, activation='relu')(dense1)\n",
        "outputs = Dense(1, activation='sigmoid')(dense1)"
      ],
      "metadata": {
        "id": "bS18qmIqBJKT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[sequences, tfidf], outputs=outputs)\n",
        "     \n",
        "\n",
        "mch = callbacks.ModelCheckpoint('../models/fianl-model-dualchanal.h5' , monitor='accuracy' , mode ='max' , save_best_only=True)\n",
        "     \n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WbeHMb7NBJPo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DualChannelDataGenerator(Sequence):\n",
        "    def __init__(self, dataset_size , seq_x_file, tfidf_x_file, y_file, batch_size):\n",
        "      self.dataset_size = dataset_size\n",
        "      with open(seq_x_file, 'rb') as f:\n",
        "          mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
        "          self.seq_x = np.load(mm, allow_pickle=True)\n",
        "      with open(tfidf_x_file, 'rb') as f:\n",
        "          mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
        "          self.tfidf_x = np.load(mm, allow_pickle=True)\n",
        "      with open(y_file, 'rb') as f:\n",
        "          mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
        "          self.y = np.load(mm, allow_pickle=True)\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.dataset_size/ float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_seq_x = self.seq_x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_tfidf_x = self.tfidf_x[idx * self.batch_size:(idx + 1) * self.batch_size].toarray()\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        return [batch_seq_x, batch_tfidf_x], batch_y\n",
        "\n"
      ],
      "metadata": {
        "id": "WoFbfZczBJVC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/persian-sentiment-analysis/X_train_tfidf1.pickle' , 'rb') as f:\n",
        "  tfidf_1 = pickle.load(f)\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/X_train_tfidf.pickle' , 'wb') as f:\n",
        "  pickle.dump(tfidf_1 , f)\n",
        "\n",
        "del tfidf_1\n"
      ],
      "metadata": {
        "id": "GTkCTh08BJZB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/persian-sentiment-analysis/X_test_tfidf.pickle' , 'rb') as f:\n",
        "  tfidf = pickle.load(f)\n",
        "\n",
        "with open('/content/X_test_tfidf.pickle' , 'wb') as f:\n",
        "  pickle.dump(tfidf , f)\n",
        "\n",
        "del tfidf\n"
      ],
      "metadata": {
        "id": "yBaYCqPzBJfj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/persian-sentiment-analysis/train_pad_sequences1.pickle' , 'rb') as f:\n",
        "  seq_1 = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/persian-sentiment-analysis/train_pad_sequences2.pickle' , 'rb') as f:\n",
        "  seq_2 = pickle.load(f)\n",
        "\n",
        "with open('/content/train_pad_sequences.pickle' , 'wb') as f:\n",
        "  pickle.dump(np.concatenate((seq_1 , seq_2), axis=0) , f)\n",
        "\n",
        "del seq_1\n",
        "del seq_2"
      ],
      "metadata": {
        "id": "AOPP_FM4BP3O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/persian-sentiment-analysis/test_pad_sequences.pickle' , 'rb') as f:\n",
        "  seq_test = pickle.load(f)\n",
        "\n",
        "with open('/content/test_pad_sequences.pickle' , 'wb') as f:\n",
        "  pickle.dump(seq_test , f)\n",
        "\n",
        "del seq_test\n",
        "     "
      ],
      "metadata": {
        "id": "Wx8UcWLDBP8C"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/persian-sentiment-analysis/train_labels.pickle' , 'rb') as f:\n",
        "  train_labels = pickle.load(f)\n",
        "\n",
        "with open('/content/train_labels.pickle' , 'wb') as f:\n",
        "  pickle.dump(train_labels, f)\n",
        "\n",
        "del train_labels"
      ],
      "metadata": {
        "id": "2DCbwcUCBQBE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/persian-sentiment-analysis/test_labels.pickle' , 'rb') as f:\n",
        "  test_labels = pickle.load(f)\n",
        "\n",
        "with open('/content/test_labels.pickle' , 'wb') as f:\n",
        "  pickle.dump(test_labels , f)\n",
        "\n",
        "del test_labels\n",
        "     "
      ],
      "metadata": {
        "id": "0eoOtQsvBQIx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "dataset_size_train = 3600000\n",
        "dataset_size_test = 400000\n",
        "seq_path_train = '/content/train_pad_sequences.pickle'\n",
        "seq_path_test =  '/content/test_pad_sequences.pickle'\n",
        "tfidf_train = '/content/X_train_tfidf.pickle'\n",
        "tfidf_test = '/content/X_test_tfidf.pickle'\n",
        "train_labels = '/content/train_labels.pickle'\n",
        "test_labels = '/content/test_labels.pickle'"
      ],
      "metadata": {
        "id": "86V_bZUdBQPJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = DualChannelDataGenerator(dataset_size_train ,seq_path_train , tfidf_train , train_labels , batch_size)\n"
      ],
      "metadata": {
        "id": "8_uDtMerBVew"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = DualChannelDataGenerator(dataset_size_test ,seq_path_test , tfidf_test , test_labels , batch_size)\n"
      ],
      "metadata": {
        "id": "IhCYFTYbBVjc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=10 , validation_data=test_generator, validation_steps=len(test_generator),callbacks=[mch])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAGsdsHsBdJD",
        "outputId": "55b49aa0-b130-4bd8-853e-ccd9060e22df"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "28125/28125 [==============================] - 564s 20ms/step - loss: 0.1609 - accuracy: 0.9382 - val_loss: 0.1446 - val_accuracy: 0.9466\n",
            "Epoch 2/10\n",
            "28125/28125 [==============================] - 339s 12ms/step - loss: 0.1293 - accuracy: 0.9525 - val_loss: 0.1368 - val_accuracy: 0.9497\n",
            "Epoch 3/10\n",
            "28125/28125 [==============================] - 340s 12ms/step - loss: 0.1172 - accuracy: 0.9576 - val_loss: 0.1326 - val_accuracy: 0.9512\n",
            "Epoch 4/10\n",
            "28125/28125 [==============================] - 339s 12ms/step - loss: 0.1079 - accuracy: 0.9616 - val_loss: 0.1350 - val_accuracy: 0.9509\n",
            "Epoch 5/10\n",
            "28125/28125 [==============================] - 337s 12ms/step - loss: 0.1003 - accuracy: 0.9648 - val_loss: 0.1388 - val_accuracy: 0.9500\n",
            "Epoch 6/10\n",
            "28125/28125 [==============================] - 336s 12ms/step - loss: 0.0937 - accuracy: 0.9674 - val_loss: 0.1454 - val_accuracy: 0.9484\n",
            "Epoch 7/10\n",
            "28125/28125 [==============================] - 347s 12ms/step - loss: 0.0880 - accuracy: 0.9698 - val_loss: 0.1463 - val_accuracy: 0.9484\n",
            "Epoch 8/10\n",
            "28125/28125 [==============================] - 339s 12ms/step - loss: 0.0830 - accuracy: 0.9718 - val_loss: 0.1584 - val_accuracy: 0.9469\n",
            "Epoch 9/10\n",
            "28125/28125 [==============================] - 334s 12ms/step - loss: 0.0787 - accuracy: 0.9736 - val_loss: 0.1592 - val_accuracy: 0.9464\n",
            "Epoch 10/10\n",
            "28125/28125 [==============================] - 342s 12ms/step - loss: 0.0747 - accuracy: 0.9752 - val_loss: 0.1693 - val_accuracy: 0.9462\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2dfc27ffa0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NTl361T2BgJi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}