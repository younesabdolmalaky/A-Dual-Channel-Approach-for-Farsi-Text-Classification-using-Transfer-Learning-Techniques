{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPS5A/c4/6YRR4Gqg8yRRS5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younesabdolmalaky/A-Dual-Channel-Approach-for-Farsi-Text-Classification-using-Transfer-Learning-Techniques/blob/main/notebooks/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsTHchjZMKEH",
        "outputId": "f03dcbb6-5953-43f7-b5f5-79a63a848a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/persian-sentiment-analysis/train_pad_sequences.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8KRAxyct4J9",
        "outputId": "4f7c8eab-6b1b-455f-f2b9-59bd500985b3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/persian-sentiment-analysis/train_pad_sequences.zip\n",
            "  inflating: content/train_pad_sequences.pickle  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input , Dense\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import bz2\n",
        "import numpy as np\n",
        "import pickle\n",
        "import mmap \n",
        "import re"
      ],
      "metadata": {
        "id": "IAcZsKiYpeJQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_FEATURES = 12000\n",
        "sequences = Input(shape=(255,))\n",
        "embedded = layers.Embedding(MAX_FEATURES, 32)(sequences)\n",
        "x = layers.Conv1D(64, 3, activation='relu')(embedded)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPool1D(3)(x)\n",
        "x = layers.Conv1D(32, 5, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPool1D(5)(x)\n",
        "x = layers.Conv1D(16, 5, activation='relu')(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)"
      ],
      "metadata": {
        "id": "0qEw4_motGxk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=sequences, outputs=outputs)"
      ],
      "metadata": {
        "id": "BAird2eLtI4-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mch = callbacks.ModelCheckpoint('../models/fianl-model-cnn.h5' , monitor='accuracy' , mode ='max' , save_best_only=True)"
      ],
      "metadata": {
        "id": "wcvb6I8DtKXL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "w2EcCDDutKpW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self , dataset_size ,x_file, y_file, batch_size=32):\n",
        "        self.dataset_size = dataset_size\n",
        "        self.x_file = x_file\n",
        "        self.y_file = y_file\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "\n",
        "        with open(x_file, 'rb') as f:\n",
        "          mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
        "          self.arr_train = np.load(mm , allow_pickle=True)\n",
        "        \n",
        "\n",
        "        with open(y_file, 'rb') as f:\n",
        "          mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
        "          self.arr_y = np.load(mm , allow_pickle=True)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil((self.dataset_size) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_X = self.arr_train[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.arr_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        return batch_X, batch_y\n",
        "batch_size = 8192\n",
        "dataset_size_train = 3600000\n",
        "dataset_size_test = 400000\n",
        "train_generator = DataGenerator(dataset_size_train,\"/content/drive/MyDrive/persian-sentiment-analysis/train_pad_sequences.pickle\", \"/content/drive/MyDrive/persian-sentiment-analysis/train_labels.pickle\", batch_size=batch_size)\n",
        "test_generator = DataGenerator(dataset_size_test,\"/content/drive/MyDrive/persian-sentiment-analysis/test_pad_sequences.pickle\", \"/content/drive/MyDrive/persian-sentiment-analysis/test_labels.pickle\", batch_size=batch_size)"
      ],
      "metadata": {
        "id": "TaaYDMRRtKuc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=100 , validation_data=test_generator, validation_steps=len(test_generator),callbacks=[mch])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_j7Se-EtQql",
        "outputId": "6c2e008e-4983-4df2-83cd-c8bc54abd7dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "440/440 [==============================] - 138s 285ms/step - loss: 0.2407 - accuracy: 0.8959 - val_loss: 0.3597 - val_accuracy: 0.9171\n",
            "Epoch 2/100\n",
            "440/440 [==============================] - 110s 251ms/step - loss: 0.1554 - accuracy: 0.9415 - val_loss: 0.1577 - val_accuracy: 0.9407\n",
            "Epoch 3/100\n",
            "440/440 [==============================] - 109s 248ms/step - loss: 0.1399 - accuracy: 0.9483 - val_loss: 0.1503 - val_accuracy: 0.9441\n",
            "Epoch 4/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.1299 - accuracy: 0.9526 - val_loss: 0.1597 - val_accuracy: 0.9399\n",
            "Epoch 5/100\n",
            "440/440 [==============================] - 112s 255ms/step - loss: 0.1225 - accuracy: 0.9558 - val_loss: 0.1512 - val_accuracy: 0.9448\n",
            "Epoch 6/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.1164 - accuracy: 0.9585 - val_loss: 0.1845 - val_accuracy: 0.9316\n",
            "Epoch 7/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.1107 - accuracy: 0.9609 - val_loss: 0.1623 - val_accuracy: 0.9406\n",
            "Epoch 8/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.1066 - accuracy: 0.9626 - val_loss: 0.1586 - val_accuracy: 0.9430\n",
            "Epoch 9/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.1025 - accuracy: 0.9644 - val_loss: 0.1618 - val_accuracy: 0.9428\n",
            "Epoch 10/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0984 - accuracy: 0.9661 - val_loss: 0.1709 - val_accuracy: 0.9414\n",
            "Epoch 11/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0949 - accuracy: 0.9676 - val_loss: 0.1759 - val_accuracy: 0.9390\n",
            "Epoch 12/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0916 - accuracy: 0.9691 - val_loss: 0.1784 - val_accuracy: 0.9399\n",
            "Epoch 13/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0889 - accuracy: 0.9702 - val_loss: 0.1846 - val_accuracy: 0.9402\n",
            "Epoch 14/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0865 - accuracy: 0.9711 - val_loss: 0.1821 - val_accuracy: 0.9398\n",
            "Epoch 15/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0838 - accuracy: 0.9723 - val_loss: 0.1850 - val_accuracy: 0.9397\n",
            "Epoch 16/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0813 - accuracy: 0.9734 - val_loss: 0.1975 - val_accuracy: 0.9386\n",
            "Epoch 17/100\n",
            "440/440 [==============================] - 112s 255ms/step - loss: 0.0797 - accuracy: 0.9741 - val_loss: 0.2308 - val_accuracy: 0.9299\n",
            "Epoch 18/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0779 - accuracy: 0.9748 - val_loss: 0.2062 - val_accuracy: 0.9385\n",
            "Epoch 19/100\n",
            "440/440 [==============================] - 112s 255ms/step - loss: 0.0757 - accuracy: 0.9758 - val_loss: 0.2078 - val_accuracy: 0.9373\n",
            "Epoch 20/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0743 - accuracy: 0.9763 - val_loss: 0.2065 - val_accuracy: 0.9357\n",
            "Epoch 21/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0724 - accuracy: 0.9771 - val_loss: 0.2030 - val_accuracy: 0.9367\n",
            "Epoch 22/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0714 - accuracy: 0.9776 - val_loss: 0.2117 - val_accuracy: 0.9368\n",
            "Epoch 23/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0699 - accuracy: 0.9782 - val_loss: 0.2104 - val_accuracy: 0.9360\n",
            "Epoch 24/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0687 - accuracy: 0.9786 - val_loss: 0.2324 - val_accuracy: 0.9357\n",
            "Epoch 25/100\n",
            "440/440 [==============================] - 110s 251ms/step - loss: 0.0676 - accuracy: 0.9791 - val_loss: 0.2317 - val_accuracy: 0.9355\n",
            "Epoch 26/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0670 - accuracy: 0.9792 - val_loss: 0.2239 - val_accuracy: 0.9360\n",
            "Epoch 27/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0659 - accuracy: 0.9798 - val_loss: 0.2308 - val_accuracy: 0.9364\n",
            "Epoch 28/100\n",
            "440/440 [==============================] - 112s 255ms/step - loss: 0.0641 - accuracy: 0.9806 - val_loss: 0.2521 - val_accuracy: 0.9327\n",
            "Epoch 29/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0636 - accuracy: 0.9807 - val_loss: 0.2370 - val_accuracy: 0.9359\n",
            "Epoch 30/100\n",
            "440/440 [==============================] - 112s 255ms/step - loss: 0.0624 - accuracy: 0.9812 - val_loss: 0.2277 - val_accuracy: 0.9356\n",
            "Epoch 31/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0621 - accuracy: 0.9814 - val_loss: 0.2369 - val_accuracy: 0.9353\n",
            "Epoch 32/100\n",
            "440/440 [==============================] - 112s 255ms/step - loss: 0.0608 - accuracy: 0.9818 - val_loss: 0.2421 - val_accuracy: 0.9324\n",
            "Epoch 33/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0604 - accuracy: 0.9819 - val_loss: 0.2491 - val_accuracy: 0.9340\n",
            "Epoch 34/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0601 - accuracy: 0.9821 - val_loss: 0.2351 - val_accuracy: 0.9349\n",
            "Epoch 35/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0591 - accuracy: 0.9825 - val_loss: 0.2713 - val_accuracy: 0.9317\n",
            "Epoch 36/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0587 - accuracy: 0.9827 - val_loss: 0.2591 - val_accuracy: 0.9341\n",
            "Epoch 37/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0575 - accuracy: 0.9830 - val_loss: 0.2533 - val_accuracy: 0.9346\n",
            "Epoch 38/100\n",
            "440/440 [==============================] - 112s 254ms/step - loss: 0.0573 - accuracy: 0.9832 - val_loss: 0.2573 - val_accuracy: 0.9333\n",
            "Epoch 39/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0560 - accuracy: 0.9837 - val_loss: 0.2713 - val_accuracy: 0.9333\n",
            "Epoch 40/100\n",
            "440/440 [==============================] - 112s 255ms/step - loss: 0.0559 - accuracy: 0.9837 - val_loss: 0.2801 - val_accuracy: 0.9300\n",
            "Epoch 41/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0555 - accuracy: 0.9839 - val_loss: 0.2760 - val_accuracy: 0.9337\n",
            "Epoch 42/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0547 - accuracy: 0.9842 - val_loss: 0.2764 - val_accuracy: 0.9342\n",
            "Epoch 43/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0542 - accuracy: 0.9843 - val_loss: 0.2717 - val_accuracy: 0.9341\n",
            "Epoch 44/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0541 - accuracy: 0.9843 - val_loss: 0.2807 - val_accuracy: 0.9335\n",
            "Epoch 45/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0540 - accuracy: 0.9844 - val_loss: 0.2879 - val_accuracy: 0.9330\n",
            "Epoch 46/100\n",
            "440/440 [==============================] - 110s 251ms/step - loss: 0.0537 - accuracy: 0.9844 - val_loss: 0.2790 - val_accuracy: 0.9342\n",
            "Epoch 47/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0522 - accuracy: 0.9851 - val_loss: 0.2805 - val_accuracy: 0.9331\n",
            "Epoch 48/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0520 - accuracy: 0.9851 - val_loss: 0.2868 - val_accuracy: 0.9335\n",
            "Epoch 49/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0511 - accuracy: 0.9855 - val_loss: 0.2989 - val_accuracy: 0.9334\n",
            "Epoch 50/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0515 - accuracy: 0.9853 - val_loss: 0.3060 - val_accuracy: 0.9337\n",
            "Epoch 51/100\n",
            "440/440 [==============================] - 109s 249ms/step - loss: 0.0507 - accuracy: 0.9856 - val_loss: 0.3045 - val_accuracy: 0.9335\n",
            "Epoch 52/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0511 - accuracy: 0.9854 - val_loss: 0.2943 - val_accuracy: 0.9333\n",
            "Epoch 53/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0497 - accuracy: 0.9859 - val_loss: 0.3078 - val_accuracy: 0.9336\n",
            "Epoch 54/100\n",
            "440/440 [==============================] - 109s 247ms/step - loss: 0.0498 - accuracy: 0.9858 - val_loss: 0.3025 - val_accuracy: 0.9322\n",
            "Epoch 55/100\n",
            "440/440 [==============================] - 110s 249ms/step - loss: 0.0491 - accuracy: 0.9861 - val_loss: 0.3166 - val_accuracy: 0.9326\n",
            "Epoch 56/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0490 - accuracy: 0.9861 - val_loss: 0.3073 - val_accuracy: 0.9336\n",
            "Epoch 57/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 0.3150 - val_accuracy: 0.9331\n",
            "Epoch 58/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0481 - accuracy: 0.9864 - val_loss: 0.3444 - val_accuracy: 0.9306\n",
            "Epoch 59/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0474 - accuracy: 0.9866 - val_loss: 0.3166 - val_accuracy: 0.9333\n",
            "Epoch 60/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0473 - accuracy: 0.9866 - val_loss: 0.3218 - val_accuracy: 0.9314\n",
            "Epoch 61/100\n",
            "440/440 [==============================] - 110s 251ms/step - loss: 0.0475 - accuracy: 0.9866 - val_loss: 0.3162 - val_accuracy: 0.9327\n",
            "Epoch 62/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0474 - accuracy: 0.9865 - val_loss: 0.3360 - val_accuracy: 0.9333\n",
            "Epoch 63/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0462 - accuracy: 0.9870 - val_loss: 0.3402 - val_accuracy: 0.9332\n",
            "Epoch 64/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0463 - accuracy: 0.9869 - val_loss: 0.3344 - val_accuracy: 0.9327\n",
            "Epoch 65/100\n",
            "440/440 [==============================] - 110s 250ms/step - loss: 0.0457 - accuracy: 0.9871 - val_loss: 0.3353 - val_accuracy: 0.9334\n",
            "Epoch 66/100\n",
            "440/440 [==============================] - 110s 251ms/step - loss: 0.0456 - accuracy: 0.9871 - val_loss: 0.3521 - val_accuracy: 0.9330\n",
            "Epoch 67/100\n",
            "440/440 [==============================] - 108s 246ms/step - loss: 0.0455 - accuracy: 0.9871 - val_loss: 0.3506 - val_accuracy: 0.9328\n",
            "Epoch 68/100\n",
            "440/440 [==============================] - 111s 252ms/step - loss: 0.0455 - accuracy: 0.9871 - val_loss: 0.3634 - val_accuracy: 0.9330\n",
            "Epoch 69/100\n",
            "440/440 [==============================] - 111s 252ms/step - loss: 0.0449 - accuracy: 0.9873 - val_loss: 0.3474 - val_accuracy: 0.9323\n",
            "Epoch 70/100\n",
            "440/440 [==============================] - 113s 256ms/step - loss: 0.0448 - accuracy: 0.9874 - val_loss: 0.3360 - val_accuracy: 0.9326\n",
            "Epoch 71/100\n",
            "440/440 [==============================] - 111s 252ms/step - loss: 0.0440 - accuracy: 0.9876 - val_loss: 0.3640 - val_accuracy: 0.9332\n",
            "Epoch 72/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0441 - accuracy: 0.9875 - val_loss: 0.3587 - val_accuracy: 0.9320\n",
            "Epoch 73/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0441 - accuracy: 0.9876 - val_loss: 0.3617 - val_accuracy: 0.9325\n",
            "Epoch 74/100\n",
            "440/440 [==============================] - 111s 252ms/step - loss: 0.0434 - accuracy: 0.9877 - val_loss: 0.3717 - val_accuracy: 0.9321\n",
            "Epoch 75/100\n",
            "440/440 [==============================] - 113s 256ms/step - loss: 0.0432 - accuracy: 0.9877 - val_loss: 0.3856 - val_accuracy: 0.9310\n",
            "Epoch 76/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0428 - accuracy: 0.9879 - val_loss: 0.3742 - val_accuracy: 0.9327\n",
            "Epoch 77/100\n",
            "440/440 [==============================] - 111s 252ms/step - loss: 0.0431 - accuracy: 0.9878 - val_loss: 0.3782 - val_accuracy: 0.9318\n",
            "Epoch 78/100\n",
            "440/440 [==============================] - 113s 256ms/step - loss: 0.0427 - accuracy: 0.9879 - val_loss: 0.3815 - val_accuracy: 0.9316\n",
            "Epoch 79/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0420 - accuracy: 0.9881 - val_loss: 0.3821 - val_accuracy: 0.9317\n",
            "Epoch 80/100\n",
            "440/440 [==============================] - 112s 256ms/step - loss: 0.0420 - accuracy: 0.9880 - val_loss: 0.3713 - val_accuracy: 0.9318\n",
            "Epoch 81/100\n",
            "440/440 [==============================] - 110s 251ms/step - loss: 0.0423 - accuracy: 0.9880 - val_loss: 0.3935 - val_accuracy: 0.9327\n",
            "Epoch 82/100\n",
            "440/440 [==============================] - 113s 256ms/step - loss: 0.0418 - accuracy: 0.9881 - val_loss: 0.4041 - val_accuracy: 0.9314\n",
            "Epoch 83/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0412 - accuracy: 0.9883 - val_loss: 0.4006 - val_accuracy: 0.9312\n",
            "Epoch 84/100\n",
            "440/440 [==============================] - 112s 256ms/step - loss: 0.0414 - accuracy: 0.9882 - val_loss: 0.3966 - val_accuracy: 0.9320\n",
            "Epoch 85/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0411 - accuracy: 0.9883 - val_loss: 0.4038 - val_accuracy: 0.9324\n",
            "Epoch 86/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0406 - accuracy: 0.9884 - val_loss: 0.4113 - val_accuracy: 0.9322\n",
            "Epoch 87/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0401 - accuracy: 0.9886 - val_loss: 0.4241 - val_accuracy: 0.9296\n",
            "Epoch 88/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0412 - accuracy: 0.9881 - val_loss: 0.4032 - val_accuracy: 0.9322\n",
            "Epoch 89/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 0.4188 - val_accuracy: 0.9323\n",
            "Epoch 90/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0394 - accuracy: 0.9887 - val_loss: 0.4167 - val_accuracy: 0.9323\n",
            "Epoch 91/100\n",
            "440/440 [==============================] - 113s 256ms/step - loss: 0.0394 - accuracy: 0.9887 - val_loss: 0.4307 - val_accuracy: 0.9314\n",
            "Epoch 92/100\n",
            "440/440 [==============================] - 110s 251ms/step - loss: 0.0397 - accuracy: 0.9886 - val_loss: 0.4191 - val_accuracy: 0.9310\n",
            "Epoch 93/100\n",
            "440/440 [==============================] - 113s 256ms/step - loss: 0.0396 - accuracy: 0.9886 - val_loss: 0.4188 - val_accuracy: 0.9306\n",
            "Epoch 94/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0392 - accuracy: 0.9887 - val_loss: 0.4277 - val_accuracy: 0.9317\n",
            "Epoch 95/100\n",
            "440/440 [==============================] - 110s 251ms/step - loss: 0.0385 - accuracy: 0.9890 - val_loss: 0.4438 - val_accuracy: 0.9323\n",
            "Epoch 96/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0385 - accuracy: 0.9889 - val_loss: 0.4305 - val_accuracy: 0.9315\n",
            "Epoch 97/100\n",
            "440/440 [==============================] - 110s 251ms/step - loss: 0.0385 - accuracy: 0.9889 - val_loss: 0.4382 - val_accuracy: 0.9311\n",
            "Epoch 98/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0387 - accuracy: 0.9888 - val_loss: 0.4506 - val_accuracy: 0.9312\n",
            "Epoch 99/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0383 - accuracy: 0.9889 - val_loss: 0.4383 - val_accuracy: 0.9312\n",
            "Epoch 100/100\n",
            "440/440 [==============================] - 111s 251ms/step - loss: 0.0376 - accuracy: 0.9892 - val_loss: 0.4493 - val_accuracy: 0.9316\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f26802d7280>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rH08GheitK0e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}